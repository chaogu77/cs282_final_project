{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Params\n",
    "image_dim = 784 # 28*28 pixels\n",
    "gen_hidden_dim = 256\n",
    "disc_hidden_dim = 256\n",
    "noise_dim = 128 # Noise data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning param\n",
    "Batch_Size = 50\n",
    "Critic_Iters = 5 # for WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "c = 0.01 # threshold for weight cliping (-c,c)\n",
    "Iters = 100001 # number of generator iterations to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Clearing all tensors before this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('g_h'):\n",
    "    g_W1 = tf.Variable(tf.random_normal([noise_dim,gen_hidden_dim]),name='g_W1')\n",
    "    g_b1 = tf.Variable(tf.random_normal([gen_hidden_dim]),name='g_b1')\n",
    "with tf.name_scope('g_o'):\n",
    "    g_W2 = tf.Variable(tf.random_normal([gen_hidden_dim,image_dim]),name='g_W2')\n",
    "    g_b2 = tf.Variable(tf.random_normal([image_dim]),name='g_b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('d_h'):\n",
    "    d_W1 = tf.Variable(tf.random_normal([image_dim,disc_hidden_dim]),name='d_W1')\n",
    "    d_b1 = tf.Variable(tf.random_normal([disc_hidden_dim]),name='d_b1')\n",
    "with tf.name_scope('g_o'):\n",
    "    d_W2 = tf.Variable(tf.random_normal([disc_hidden_dim,1]),name='d_W2')\n",
    "    d_b2 = tf.Variable(tf.random_normal([1]),name='d_b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "with tf.name_scope('Generator'):\n",
    "    def generator(noises, reuse=False):\n",
    "        with tf.variable_scope('generator') as scope:\n",
    "            if (reuse):\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            # hidden layer with name \"g_hidden\"\n",
    "            hidden = tf.nn.relu(noises @ g_W1 + g_b1, name='gen_hidden')\n",
    "            # out layer with name \"g_out\"\n",
    "            out_images = tf.nn.sigmoid(hidden @ g_W2 + g_b2, name='gen_out')\n",
    "        return out_images\n",
    "\n",
    "# Discriminator\n",
    "with tf.name_scope('Discriminator'):\n",
    "    def discriminator(images, reuse=False):\n",
    "        with tf.variable_scope('discriminator') as scope:\n",
    "            if (reuse):\n",
    "                tf.get_variable_scope().reuse_variables()            \n",
    "            # hidden layer with name \"d_hidden\"\n",
    "            hidden = tf.nn.relu(images @ d_W1 + d_b1, name='disc_hidden')\n",
    "            # out layer with name \"d_out\"\n",
    "            out = tf.add(hidden @ d_W2, d_b2,name = 'disc_out')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = generator(gen_input)\n",
    "real_data = tf.placeholder(tf.float32, shape=[None, image_dim], name='real_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_real = discriminator(real_data)\n",
    "disc_fake = discriminator(fake_data, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cost = -tf.reduce_mean(disc_fake)\n",
    "disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "disc_vars = [var for var in tvars if 'd_' in var.name]\n",
    "gen_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.train.RMSPropOptimizer(\n",
    "        learning_rate=5e-5, \n",
    "    ).minimize(gen_cost, var_list=gen_vars)\n",
    "\n",
    "train_disc = tf.train.RMSPropOptimizer(\n",
    "        learning_rate=5e-5, \n",
    "    ).minimize(disc_cost, var_list=disc_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_D = [p.assign(tf.clip_by_value(p,-c,c)) for p in disc_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    loss = tf.summary.scalar('loss',-disc_cost)\n",
    "    \n",
    "    gen_W1 = tf.summary.scalar('g_W1',tf.reduce_mean(g_W1))\n",
    "    gen_b1 = tf.summary.scalar('g_b1',tf.reduce_mean(g_b1))\n",
    "    gen_W2 = tf.summary.scalar('g_W2',tf.reduce_mean(g_W2))\n",
    "    gen_b2 = tf.summary.scalar('g_b2',tf.reduce_mean(g_b2))\n",
    "    \n",
    "    disc_W1 = tf.summary.scalar('d_W1',tf.reduce_mean(d_W1))\n",
    "    disc_b1 = tf.summary.scalar('d_b1',tf.reduce_mean(d_b1))\n",
    "    disc_W2 = tf.summary.scalar('d_W2',tf.reduce_mean(d_W2))\n",
    "    disc_bb = tf.summary.scalar('d_b2',tf.reduce_mean(d_b2))\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator Loss: -0.030171, Discriminator Loss: 0.006845\n",
      "wgan0.png\n",
      "Step 1000: Generator Loss: 3.036338, Discriminator Loss: -4.047624\n",
      "Step 2000: Generator Loss: 2.382365, Discriminator Loss: -3.344711\n",
      "Step 3000: Generator Loss: 1.920176, Discriminator Loss: -2.619874\n",
      "Step 4000: Generator Loss: 1.828283, Discriminator Loss: -1.996676\n",
      "Step 5000: Generator Loss: 1.579008, Discriminator Loss: -1.345547\n",
      "Step 6000: Generator Loss: 1.059629, Discriminator Loss: -0.808251\n",
      "Step 7000: Generator Loss: 0.542241, Discriminator Loss: -0.546072\n",
      "Step 8000: Generator Loss: 0.339209, Discriminator Loss: -0.327073\n",
      "Step 9000: Generator Loss: 0.133321, Discriminator Loss: -0.249634\n",
      "Step 10000: Generator Loss: 0.304174, Discriminator Loss: -0.192467\n",
      "wgan10000.png\n",
      "Step 11000: Generator Loss: 0.219131, Discriminator Loss: -0.160862\n",
      "Step 12000: Generator Loss: 0.235771, Discriminator Loss: -0.195546\n",
      "Step 13000: Generator Loss: 0.172058, Discriminator Loss: -0.131068\n",
      "Step 14000: Generator Loss: 0.159810, Discriminator Loss: -0.124436\n",
      "Step 15000: Generator Loss: 0.112123, Discriminator Loss: -0.132422\n",
      "Step 16000: Generator Loss: 0.100379, Discriminator Loss: -0.120124\n",
      "Step 17000: Generator Loss: -0.155704, Discriminator Loss: -0.186588\n",
      "Step 18000: Generator Loss: -0.148429, Discriminator Loss: -0.154248\n",
      "Step 19000: Generator Loss: -0.189886, Discriminator Loss: -0.130497\n",
      "Step 20000: Generator Loss: -0.080421, Discriminator Loss: -0.176069\n",
      "wgan20000.png\n",
      "Step 21000: Generator Loss: 0.012809, Discriminator Loss: -0.119464\n",
      "Step 22000: Generator Loss: 0.035405, Discriminator Loss: -0.141576\n",
      "Step 23000: Generator Loss: -0.072865, Discriminator Loss: -0.146317\n",
      "Step 24000: Generator Loss: 0.161550, Discriminator Loss: -0.124454\n",
      "Step 25000: Generator Loss: -0.038583, Discriminator Loss: -0.142404\n",
      "Step 26000: Generator Loss: 0.026207, Discriminator Loss: -0.233983\n",
      "Step 27000: Generator Loss: -0.030692, Discriminator Loss: -0.154682\n",
      "Step 28000: Generator Loss: 0.011399, Discriminator Loss: -0.208728\n",
      "Step 29000: Generator Loss: -0.017832, Discriminator Loss: -0.190941\n",
      "Step 30000: Generator Loss: 0.015938, Discriminator Loss: -0.180431\n",
      "wgan30000.png\n",
      "Step 31000: Generator Loss: -0.037291, Discriminator Loss: -0.195920\n",
      "Step 32000: Generator Loss: 0.003746, Discriminator Loss: -0.194940\n",
      "Step 33000: Generator Loss: -0.009908, Discriminator Loss: -0.205516\n",
      "Step 34000: Generator Loss: -0.005302, Discriminator Loss: -0.200537\n",
      "Step 35000: Generator Loss: -0.011777, Discriminator Loss: -0.203550\n",
      "Step 36000: Generator Loss: 0.001595, Discriminator Loss: -0.208139\n",
      "Step 37000: Generator Loss: -0.025418, Discriminator Loss: -0.200090\n",
      "Step 38000: Generator Loss: -0.009839, Discriminator Loss: -0.174872\n",
      "Step 39000: Generator Loss: -0.029098, Discriminator Loss: -0.172433\n",
      "Step 40000: Generator Loss: -0.032447, Discriminator Loss: -0.159512\n",
      "wgan40000.png\n",
      "Step 41000: Generator Loss: -0.006394, Discriminator Loss: -0.172661\n",
      "Step 42000: Generator Loss: -0.004035, Discriminator Loss: -0.175944\n",
      "Step 43000: Generator Loss: 0.006748, Discriminator Loss: -0.200495\n",
      "Step 44000: Generator Loss: -0.015997, Discriminator Loss: -0.169562\n",
      "Step 45000: Generator Loss: -0.017223, Discriminator Loss: -0.168769\n",
      "Step 46000: Generator Loss: -0.012467, Discriminator Loss: -0.166231\n",
      "Step 47000: Generator Loss: -0.021082, Discriminator Loss: -0.183604\n",
      "Step 48000: Generator Loss: -0.021335, Discriminator Loss: -0.163024\n",
      "Step 49000: Generator Loss: -0.026566, Discriminator Loss: -0.144590\n",
      "Step 50000: Generator Loss: -0.025291, Discriminator Loss: -0.146281\n",
      "wgan50000.png\n",
      "Step 51000: Generator Loss: -0.007728, Discriminator Loss: -0.183356\n",
      "Step 52000: Generator Loss: -0.030961, Discriminator Loss: -0.129286\n",
      "Step 53000: Generator Loss: -0.013988, Discriminator Loss: -0.173181\n",
      "Step 54000: Generator Loss: -0.013382, Discriminator Loss: -0.189885\n",
      "Step 55000: Generator Loss: -0.014023, Discriminator Loss: -0.157001\n",
      "Step 56000: Generator Loss: -0.005992, Discriminator Loss: -0.189569\n",
      "Step 57000: Generator Loss: -0.017457, Discriminator Loss: -0.197277\n",
      "Step 58000: Generator Loss: 0.013883, Discriminator Loss: -0.213810\n",
      "Step 59000: Generator Loss: -0.012717, Discriminator Loss: -0.165205\n",
      "Step 60000: Generator Loss: -0.013807, Discriminator Loss: -0.147491\n",
      "wgan60000.png\n",
      "Step 61000: Generator Loss: -0.020917, Discriminator Loss: -0.175393\n",
      "Step 62000: Generator Loss: -0.021564, Discriminator Loss: -0.150660\n",
      "Step 63000: Generator Loss: -0.015686, Discriminator Loss: -0.151335\n",
      "Step 64000: Generator Loss: -0.038437, Discriminator Loss: -0.145753\n",
      "Step 65000: Generator Loss: -0.011742, Discriminator Loss: -0.160516\n",
      "Step 66000: Generator Loss: -0.020808, Discriminator Loss: -0.166343\n",
      "Step 67000: Generator Loss: -0.004868, Discriminator Loss: -0.164096\n",
      "Step 68000: Generator Loss: -0.013431, Discriminator Loss: -0.161672\n",
      "Step 69000: Generator Loss: -0.000529, Discriminator Loss: -0.145350\n",
      "Step 70000: Generator Loss: -0.000071, Discriminator Loss: -0.180191\n",
      "wgan70000.png\n",
      "Step 71000: Generator Loss: -0.029710, Discriminator Loss: -0.166187\n",
      "Step 72000: Generator Loss: -0.017452, Discriminator Loss: -0.170902\n",
      "Step 73000: Generator Loss: -0.025857, Discriminator Loss: -0.153751\n",
      "Step 74000: Generator Loss: -0.033604, Discriminator Loss: -0.134920\n",
      "Step 75000: Generator Loss: -0.010100, Discriminator Loss: -0.170437\n",
      "Step 76000: Generator Loss: -0.022255, Discriminator Loss: -0.140640\n",
      "Step 77000: Generator Loss: -0.034426, Discriminator Loss: -0.174711\n",
      "Step 78000: Generator Loss: -0.022542, Discriminator Loss: -0.150670\n",
      "Step 79000: Generator Loss: -0.040304, Discriminator Loss: -0.128539\n",
      "Step 80000: Generator Loss: -0.021030, Discriminator Loss: -0.160914\n",
      "wgan80000.png\n",
      "Step 81000: Generator Loss: -0.046448, Discriminator Loss: -0.121246\n",
      "Step 82000: Generator Loss: -0.011674, Discriminator Loss: -0.164301\n",
      "Step 83000: Generator Loss: -0.017303, Discriminator Loss: -0.162141\n",
      "Step 84000: Generator Loss: -0.030849, Discriminator Loss: -0.145098\n",
      "Step 85000: Generator Loss: -0.034754, Discriminator Loss: -0.144001\n",
      "Step 86000: Generator Loss: -0.032093, Discriminator Loss: -0.148274\n",
      "Step 87000: Generator Loss: -0.034810, Discriminator Loss: -0.152224\n",
      "Step 88000: Generator Loss: -0.020742, Discriminator Loss: -0.152000\n",
      "Step 89000: Generator Loss: -0.035421, Discriminator Loss: -0.132147\n",
      "Step 90000: Generator Loss: -0.022510, Discriminator Loss: -0.167022\n",
      "wgan90000.png\n",
      "Step 91000: Generator Loss: -0.020156, Discriminator Loss: -0.149324\n",
      "Step 92000: Generator Loss: -0.029042, Discriminator Loss: -0.145905\n",
      "Step 93000: Generator Loss: -0.026191, Discriminator Loss: -0.137962\n",
      "Step 94000: Generator Loss: -0.018112, Discriminator Loss: -0.145547\n",
      "Step 95000: Generator Loss: -0.037533, Discriminator Loss: -0.148591\n",
      "Step 96000: Generator Loss: -0.000129, Discriminator Loss: -0.165098\n",
      "Step 97000: Generator Loss: -0.010219, Discriminator Loss: -0.161701\n",
      "Step 98000: Generator Loss: -0.005622, Discriminator Loss: -0.181169\n",
      "Step 99000: Generator Loss: -0.001201, Discriminator Loss: -0.179579\n",
      "Step 100000: Generator Loss: -0.006554, Discriminator Loss: -0.164484\n",
      "wgan100000.png\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('WGAN_log',sess.graph, flush_secs = 30)\n",
    "    for step in range(Iters):\n",
    "\n",
    "        batch_x, _ = mnist.train.next_batch(Batch_Size)\n",
    "        # Generate noise to feed to the generator\n",
    "        z = np.random.uniform(-1., 1., size=[Batch_Size, noise_dim])\n",
    "        \n",
    "        # train discriminator\n",
    "        for i in range(Critic_Iters):\n",
    "            _,dl = sess.run([train_disc,disc_cost],\n",
    "                                   feed_dict={real_data:batch_x,gen_input:z})\n",
    "            _ = sess.run(clip_D)\n",
    "        \n",
    "        # train generator\n",
    "        _,gl=sess.run([train_gen,gen_cost],\n",
    "                      feed_dict={gen_input:z})\n",
    "        \n",
    "        # keep log\n",
    "        if step % 1000 == 0:\n",
    "            print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (step, gl, dl))\n",
    "        if step % 100 == 0:\n",
    "            summary = sess.run(summary_op,feed_dict={gen_input:z, real_data:batch_x})\n",
    "            writer.add_summary(summary,global_step = step)\n",
    "            \n",
    "        # Generate images from noise, using the generator network.\n",
    "        if step % 10000 == 0:\n",
    "            f, a = plt.subplots(4, 10, figsize=(10, 4))\n",
    "            for i in range(10):\n",
    "                # Noise input.\n",
    "                z = np.random.uniform(-1., 1., size=[4, noise_dim])\n",
    "                g = sess.run([fake_data], feed_dict={gen_input: z})\n",
    "                g = np.reshape(g, newshape=(4, 28, 28, 1))\n",
    "                # Reverse colours for better display\n",
    "                g = -1 * (g - 1)\n",
    "                \n",
    "                for j in range(4):\n",
    "                    # Generate image from noise. Extend to 3 channels for matplot figure.\n",
    "                    img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 3, axis=2),\n",
    "                                     newshape=(28, 28, 3))\n",
    "                    a[j][i].imshow(img)\n",
    "\n",
    "            plt.draw()\n",
    "            print('wgan'+str(step)+'.png')\n",
    "            plt.savefig('wgan'+str(step)+'.png')\n",
    "    print('Done!')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_workshop]",
   "language": "python",
   "name": "conda-env-tensorflow_workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
